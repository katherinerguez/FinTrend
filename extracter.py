import streamlit as st
import pandas as pd
import json
import os
import plotly.express as px
import plotly.graph_objects as go
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import StandardScaler
from datetime import datetime, timedelta
import dask.dataframe as dd
import dask.bag as db
from hdfs import InsecureClient

st.write(1)
# Configuraci√≥n de la p√°gina
#st.set_page_config(page_title="An√°lisis Hist√≥rico Financiero", layout="wide")
st.title("üìä An√°lisis Hist√≥rico de Datos Financieros")
st.write("En la era de la informaci√≥n, los datos financieros hist√≥ricos son tu activo m√°s valioso, donde analizar, comprender y aprovechar el pasado puede ayudarte a construir un futuro financiero s√≥lido."
"Este estudio lo estaremos llevando hacia una de las empresas que alberga m√°s patentes que ninguna otra empresa de tecnolog√≠a de Estados Unidos, IBM (International Business Machines Corporation).")
#st.image("ibm.jpg", width=300)

def load_data(hdfs_url, directory_path):
    # Crear un cliente HDFS fuera del paralelismo
    client = InsecureClient(hdfs_url)

    # Listar archivos en el directorio de HDFS
    try:
        raw_list = client.list(directory_path, status=True)
    except Exception as e:
        st.error(f"Error al listar archivos en HDFS: {e}")
        return dd.DataFrame()  # Retorna un Dask DataFrame vac√≠o en caso de error

    # Filtrar solo archivos no vac√≠os
    file_paths = [
        f"{directory_path}{name}"
        for name, metadata in raw_list
        if metadata['type'] == 'FILE' and metadata['length'] > 0
    ]

    # Si no hay archivos v√°lidos, retorna un DataFrame vac√≠o inmediatamente
    if not file_paths:
        st.warning("No se encontraron archivos JSON v√°lidos en el directorio especificado.")
        return dd.DataFrame()

    # Crear una funci√≥n independiente para leer un archivo
    def read_json_file(file_path):
      try:
        with client.read(file_path) as reader:
            # Verificar si el archivo est√° vac√≠o
            content = reader.read()
            if not content.strip():
                st.warning(f"El archivo {file_path} est√° vac√≠o.")
                return []

            # Intentar cargar el JSON
            raw_data = json.loads(content)
            # Verificar si contiene las claves 'data' y 'timestamp'
            if "data" in raw_data and "timestamp" in raw_data:
                # Agregar el 'timestamp' a cada registro en 'data'
                for record in raw_data["data"]:
                    record["timestamp"] = raw_data["timestamp"]
                return raw_data["data"]
            else:
                st.warning(f"El archivo {file_path} no contiene la clave 'data' o 'timestamp'.")
                return []
      except json.JSONDecodeError as e:
        return []
      except Exception as e:
        st.warning(f"Error al leer el archivo {file_path}: {e}")
        return []

    # Procesar los archivos usando una lista en lugar de un Bag
    all_data = []
    for file_path in file_paths:
        all_data.extend(read_json_file(file_path))

    # Verificar si hay datos v√°lidos
    if not all_data:
        st.warning("No se encontraron datos v√°lidos en los archivos JSON.")
        return dd.DataFrame()

    # Convertir los datos en un Dask DataFrame
    try:
        df = dd.from_pandas(pd.DataFrame(all_data), npartitions=1)
    except Exception as e:
        st.error(f"Error al convertir los datos en DataFrame: {e}")
        return dd.DataFrame()

    return df

# Par√°metros para la carpeta local
directory_path = "/user/data/ibm_options/"  

HDFS_URL = 'http://172.19.0.4:9870'

try:
    data = load_data(HDFS_URL,directory_path)
except Exception as e:
    st.error(f"Error al cargar los datos desde la carpeta local: {e}")
    st.stop()

# Verificar si hay datos
if data.shape[0].compute() == 0:  # Verifica si hay filas en el DataFrame
    st.error("No se encontraron datos v√°lidos en los archivos JSON.")
    st.stop()

# Convertir columnas num√©ricas a tipos adecuados
numeric_columns = ["strike", "last", "mark", "bid", "ask", "volume", "open_interest",
                   "implied_volatility", "delta", "gamma", "theta", "vega", "rho"]
for col in numeric_columns:
    if col in data.columns:
        data[col] = dd.to_numeric(data[col], errors="coerce")

# Convertir la columna 'timestamp' a datetime
if 'timestamp' in data.columns:
    data['timestamp'] = dd.to_datetime(data['timestamp'], errors="coerce")
else:
    st.warning("No se encontr√≥ la columna 'timestamp' en los datos. Se agregar√° una columna simulada.")
    data['timestamp'] = dd.from_pandas(pd.Series([datetime.now() - timedelta(minutes=i) for i in range(len(data))]), npartitions=1)

# Obtener el tiempo m√≠nimo y m√°ximo de los datos
min_timestamp = data['timestamp'].min().compute()
max_timestamp = data['timestamp'].max().compute()

# Filtrado de datos
st.sidebar.header("Filtros")
type_filter = st.sidebar.multiselect("Selecciona tipo de opci√≥n", options=data["type"].unique().compute())

# Aplicar filtros
filtered_data = data
if type_filter:
    filtered_data = filtered_data[filtered_data["type"].isin(type_filter)]

if filtered_data.shape[0].compute() == 0:
    st.warning("No hay datos disponibles para los filtros seleccionados.")

# Seleccionar rango de tiempo basado en los datos disponibles
st.sidebar.header("Rango de Tiempo")
st.sidebar.write(f"Rango de tiempo disponible: {min_timestamp} a {max_timestamp}")

# Opciones de rango de tiempo
time_options = {
    "√öltimos 5 minutos": timedelta(minutes=5),
    "√öltimos 15 minutos": timedelta(minutes=15),
    "√öltimos 30 minutos": timedelta(minutes=30),
    "Todo": max_timestamp - min_timestamp
}

# Seleccionar rango de tiempo
selected_range = st.sidebar.selectbox("Selecciona el rango de tiempo", list(time_options.keys()))

# Calcular el tiempo de inicio basado en la selecci√≥n del usuario
if selected_range == "Todo":
    start_time = min_timestamp
else:
    start_time = max_timestamp - time_options[selected_range]

if start_time < min_timestamp:
    st.sidebar.warning(f"El rango seleccionado no est√° completamente disponible. Ajustando al tiempo m√≠nimo: {min_timestamp}")
    start_time = min_timestamp

# Filtrar datos por rango de tiempo
filtered_data = filtered_data[filtered_data['timestamp'] >= start_time]

# Visualizaci√≥n de m√©tricas
st.subheader("Gr√°ficos de M√©tricas Financieras")

# Gr√°fico de l√≠neas para las m√©tricas
st.write("A continuaci√≥n se genera un gr√°fico de l√≠neas que muestra la evoluci√≥n temporal de una m√©trica financiera seleccionada por el usuario."
"Con lo cual se puede apreciar patrones en las m√©tricas, se puede llevar a cabo un monitoreo y ver c√≥mo cambian y ayudar a identificar cu√°l es el mejor momento para venta o compra.")
metric_column = st.selectbox("Selecciona la m√©trica financiera a analizar", numeric_columns)

# Gr√°fico con timestamp en el eje x
fig = px.line(
    filtered_data.compute(),
    x='timestamp',  # Usar la columna 'timestamp' en el eje x
    y=metric_column,
    color="symbol",  
    title=f"Evoluci√≥n de {metric_column}",
    labels={"timestamp": "Tiempo", metric_column: metric_column}
)
st.plotly_chart(fig, use_container_width=True)

# Distribuci√≥n de la m√©trica seleccionada
st.subheader("Distribuci√≥n de la M√©trica Seleccionada")
st.write("De acuerdo a la m√©trica seleccionada anteriormente se muestra un histograma que representa su distribuci√≥n. Eval√∫a si los precios o vol√∫menes siguen una distribuci√≥n normal o tienen sesgos. "
"Se detecta outliers en las m√©tricas y analizar la dispersi√≥n de m√©tricas como volatilidad impl√≠cita para medir incertidumbre.")
fig_hist = px.histogram(
    filtered_data.compute(),
    x=metric_column,
    nbins=30,
    title=f"Distribuci√≥n de {metric_column}"
)
st.plotly_chart(fig_hist, use_container_width=True)

# Comparar contratos Call y Put
st.subheader("Comparaci√≥n entre Opciones Call y Put")
st.write("Compara el volumen y el inter√©s abierto (open interest) entre opciones Call y Put. Se puede apreciar los sentimientos del mercado que se√±ala que altos vol√∫menes en Call pueden indicar expectativas alcistas"
"y altos vol√∫menes en Put pueden indicar expectativas bajistas. El open interest ayuda a evaluar la liquidez de las opciones.")
call_put_comparison = filtered_data.groupby("type")[["volume", "open_interest"]].sum().reset_index().compute()
fig_bar = px.bar(
    call_put_comparison,
    x="type",
    y=["volume", "open_interest"],
    barmode="group",
    title="Volumen y Open Interest"
)
st.plotly_chart(fig_bar, use_container_width=True)

data['expiration'] = dd.to_datetime(data['expiration'])

# Calcular d√≠as hasta la expiraci√≥n
data['days_to_expiry'] = (data['expiration'] - datetime.now()).dt.days

# Preparaci√≥n de datos para el modelo
features = ['strike', 'implied_volatility', 'days_to_expiry', 'delta', 'gamma', 'theta', 'vega', 'rho']
X = data[features]
y = data['last']  # Usamos 'last' como variable objetivo (precio de la opci√≥n)

# Eliminar filas con valores nulos
X = X.dropna()
y = y[X.index]

# Normalizaci√≥n de caracter√≠sticas
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X.compute())

# Divisi√≥n de datos
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y.compute(), test_size=0.2, random_state=42)

# Entrenamiento del modelo
model = RandomForestRegressor(random_state=42)
model.fit(X_train, y_train)

# Interfaz de usuario para predicciones
st.sidebar.header("Par√°metros de Entrada")
strike = st.sidebar.number_input("Strike Price", value=100.0)
volatility = st.sidebar.number_input("Volatilidad Impl√≠cita", value=0.2)
days_to_expiry = st.sidebar.number_input("D√≠as hasta la Expiraci√≥n", value=30)
delta = st.sidebar.number_input("Delta", value=0.5)
gamma = st.sidebar.number_input("Gamma", value=0.01)
theta = st.sidebar.number_input("Theta", value=-0.05)
vega = st.sidebar.number_input("Vega", value=0.1)
rho = st.sidebar.number_input("Rho", value=0.01)

# Predicci√≥n
if st.sidebar.button("Predecir"):
    input_data = pd.DataFrame({
        'strike': [strike],
        'implied_volatility': [volatility],
        'days_to_expiry': [days_to_expiry],
        'delta': [delta],
        'gamma': [gamma],
        'theta': [theta],
        'vega': [vega],
        'rho': [rho]
    })
    input_scaled = scaler.transform(input_data)
    prediction = model.predict(input_scaled)
    st.write(f"El precio predicho de la opci√≥n es: {prediction[0]:.2f}")

st.subheader("Predicciones vs Valores Reales")
# Evaluaci√≥n del modelo
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
st.write("Se utilizan los datos hist√≥ricos y modelos avanzados para identificar tendencias y patrones ocultos, ofreci√©ndote una ventaja estrat√©gica en tus decisiones de inversi√≥n. "
        f"Como modelo se emplea Random Forest. Es un modelo robusto que maneja bien relaciones no lineales entre las caracter√≠sticas y el objetivo. Esto es importante en finanzas, donde las relaciones entre variables pueden ser complejas. Al evaluar el modelo el Error Cuadr√°tico Medio (MSE) fue de {mse:.2f}, por lo que el modelo es bueno")

# Gr√°fico de predicciones vs valores reales
fig = px.scatter(
    x=y_test,
    y=y_pred,
    labels={'x': 'Valores Reales', 'y': 'Predicciones'},
    title="Comparaci√≥n entre Valores Reales y Predicciones"
)
fig.add_trace(go.Scatter(x=[min(y_test), max(y_test)], y=[min(y_test), max(y_test)], mode='lines', name='L√≠nea Ideal'))
st.plotly_chart(fig, use_container_width=True)

# Gr√°fico de importancia de caracter√≠sticas
st.subheader("Importancia de las Caracter√≠sticas")
st.write("Para mostrar la importancia relativa de cada caracter√≠stica en las predicciones del modelo se utiliza un gr√°fico de barras. Esto nos ayuda a entender qu√© factores tienen m√°s influencia en el precio de la opci√≥n.")
importances = model.feature_importances_
feature_importance_df = pd.DataFrame({'Feature': features, 'Importance': importances})
fig_importance = px.bar(
    feature_importance_df,
    x='Feature',
    y='Importance',
    title="Importancia de las Caracter√≠sticas en el Modelo"
)
st.plotly_chart(fig_importance, use_container_width=True)

